\chapter{Introduction}    
    \abbrv{LRL}{Low-resource Language}
This chapter presents the stakes, scope and purpose of the present dissertation. Particularly, the third section brings to light the role that educational technologies have to play in either supporting or further endangering low resource languages (LRLs), depending on whether the technology is meant to teach languages already endangering other languages. This section can be read as a general introduction to the field of educational technologies for those concerned with the fate of LRLs or as an introduction to the concerns of LRLs for those involved in the field of educational technologies.

\section{Structure of the Dissertation}
This dissertation introduces Leksis, a new recognition vocabulary designed test tailored for LRLs. This first chapter explains the rational behind such a test. The second chapter brings together parts of the available literature from different fields ranging from applied linguistics to information theory in order to set the ground for scalable vocabulary tests adapted to the limitations and context of LRLs. The third chapter present an initial test design for the Breton language. The fourth chapter analyses the results from the test to assess the relevance of the design choices. Finally, the fifth chapters assesses the value and limitations of the test, as well as presenting an informed opinion on the needs specific to LRLs in regards to both educational and language technologies.

\section{Aim, Objectives and Research Question}
LRLs face peculiar challenges in a world where data science made quantity the mother of all qualities. The ultimate aim motivating the present work is low resource languages teaching optimisation. The essential problem of any optimisation being the metric one aims to optimize, this lead to the development of rapid, minimalist language tests that will be introduced here. Especially, the objective is to find ways to make up for the resource scarcity problem by developing methods and techniques designed to work in this scarcity context first, instead of porting to LRLs methods and techniques that too data intensive.\\
For these reason, we propose the following research question. \textit{Can language proficiency progress be measured in low resource languages?}\\
Of course, the time constraints of this dissertation cannot allow for a large scale study of the progress in language proficiency of entire groups of learners during the full extent of a course. But by studying thoroughly the literature and presenting early evaluation, we intend to be able to propose a solid argument by the end of this work.

\section{Background and Motivation}
    \subsection{Terminology: AIED and EdTech}
        \abbrv{EdTech}{Education Technologies}
        \abbrv{AIED}{AI in Education}
Modern academic research on educational technologies primarily falls under the ``AI in Education'' (AIED or AIEd) umbrella. This terminology dominates the field because of the ``International AIED Society'', founded in 1993, and the structuring impact of its journal issues and conferences. However, AIED may at time be used somewhat interchangeably with EdTech, for ``Educational Technologies'', which is a more product and market oriented terminology, a term that relates more to other neologisms like ``FinTech'', ``BioTech'' etc\ldots Educational companies such as Duolingo or Rocket Language may be considered as EdTech companies for the industry, but belonging to the field of AIED for researchers. In yet another formulation, EdTech is AIED with a business model.

    \subsection{Lower Resource Language in Educational Technologies}
        \abbrv{NLP}{Natural Language Processing}
        \abbrv{WEIRD}{Western, Educated, Industrialized, Rich and Democratic}
The question of LRLs in AIED is tightly correlated with their general situation in the field of natural language processing (NLP). The situation is best described in \textcite{magueresse_low-resource_2020}, as statistical, connectionist, methods became dominant in NLP, the question of data scarcity becomes the main limiting factor in the application of modern NLP solutions for LRLs. This problem is also compounded with a general WEIRD bias in cognitive science \parencite{henrich_most_2010}, where languages from cultures that are wealthy, educated, industrialised, rich and democratic tend to be privileged in all fields of cognitive sciences. However, if the adoption of these technologies is the most limited for LRLs, it is ironically these languages that stands the most to lose from not adopting them. Not adopting these technologies can cause a loss of visibility, prestige and desirability, which in turn leads to a lesser adoption and usage, leading to a vicious circle where less training resources are available to adapt these technologies to LRLs. This phenomenon as been described as the digital stagnation, or death, of a language, which is the online signature of socially extinct languages \parencite{kornai_digital_2013}.\\
The role educational technologies could play in breaking this vicious circle, at least for some of the languages concerned, cannot be understated. On the one hand, helping to adapt existing educational technologies to LRLs languages can help to maintain their relevance as a teaching medium for parents who wish the best educational standards for their children and offer people seeking intellectual fulfilment an alternative to simply abandoning their mother tongue to keep learning new things. It is understood that NLP technologies such as automated translation can help to port established educational technologies to a large number of linguistic communities which do not possess the resources to otherwise develop their own educational tools \parencite{haddow_survey_2022}. A study by \textcite{horbach_crosslingual_2024} supports the idea that educational equality can be achieved through cross-lingual scoring systems, in the context where open questions are used to assess skills, and where different linguistic backgrounds may impact the fluency of the students answers regardless of their understanding of the concept assessed. On the other hand, when it comes to language oriented educational technologies, the field is almost entirely dominated by research to teach English, and even coming in concurrence to already endangered languages. A paper by \textcite{henkel_supporting_2025} is symptomatic of those risks.
In this study, English speech recognition technologies are used in an AIED system to improve literacy in Ghanaian schools, a country home to more than 70 indigenous languages \parencite{noauthor_ghana_nodate}.
To the best of our knowledge, it seems that little effort have been engaged in the academic literature to support the development of educational technologies specifically tailored for the needs of LRLs and their speaking communities, despite all the progress made in recent years to develop these languages in NLP\@. This lack of evidence may be caused by a language barrier, but this only reinforce the idea that more should, if must not, be done to support LRLs in AIED\@.

    \subsection{Artificial Intelligence and Education}
    \abbrv{DL}{Deep Learning}
    \abbrv{AI}{Artificial Intelligence}
As exposed by \textcite{doroudi_intertwined_2023}, artificial intelligence (AI) and research in education entertained a 70 years long dialectic that benefited the two fields of cognitive sciences. If early works on AI initially drew from developmental psychology and even developed educational tools as part of their endeavour to emulate human intelligence with machines, it is now the field of education that benefits from the possibilities unlocked by AI technologies.

Early research in artificial intelligence explored two different approaches to try to emulate cognitive processes. The first is commonly known as Good Old-Fashioned AI (GOFAI\abbrv{GOFAI}{Good Old Fashioned AI}), it was centred around a symbolic approach that stemmed from Allen Newell, Herbert A. Simon and Cliff Shaw's seminary work on the Logic Theorist \parencite{newell_logic_1956}. This approach sought to understand how experts solve problems using rules-based systems and symbolic abstractions. The second, connectionist, approach was centred around neural networks and focused on the acquisition of cognitive skills over performance proper. It was developed by people like Marvin Minsky, Seymour Papert and many others \parencite{doroudi_intertwined_2023}. Papert notably, came to the AI world after having studied children cognitive development in Jean Piaget's laboratory in Geneva. He brought to the connectionist paradigm in AI a consequent influence from Piaget's constructionism, which is a theory that posits that learners build their skills and understanding on the knowledge and skills already acquired.

Both approaches led to attempts to create interactive educational systems early on. Examples of early educational software programs based on GOFAI comprise the GUIDON system, which relied on the Mycin engine, an infection diagnosis system, to teach students diagnosing pathologies \parencite{william_j_guidon_1983}. The connectionist branch privileged the development of educative "micro-worlds", such as educative programming languages, in which children could learn unspecified problem-solving skills. Instances of such approach comprise the Logo programming language, designed to learn about relative positioning and geometry by designing programs to guide (drawing) robot turtles. Many systems followed Logo, like the Scratch programming language and the Lego Mindstorms kits. But the necessary specialization in AI led later research to strictly focus on computer systems performance, especially as the advent of back-propagation gave rise to deep learning (DL), achieving to establish the supremacy of the connectionist paradigm in AI.

At this point, the focus definitely shifted from using developmental psychology to support AI, to integrate AI technical solutions in educational tools. A meta-analysis by \textcite{schmid_meta-analysis_2023} now supports the benefits of constructivist educational approaches like Blended Learning (BL) \abbrv{BL}{Blended Learning} and the Flipped Classroom (FC) \abbrv{FC}{Flipped Classroom}, which give more of a coaching role to teachers, with the charge of the instruction being deported to online interactive systems, most often used outside the classroom.

In this section, we saw how Piaget's constructivist ideas in education first infused in the connectionist approach to AI through Seymour Papert's works. Then, when this connectionist approach took the world by storm with the advent of DL, AI came back to education in the form of adaptive learning platforms to support constructionist practices development in schools. Learning about this combined history goes beyond a mere inquiry for historical anecdotes, it gives us the scope and epistemological framework to fix the goals and methods of educational technologies, which is a necessary step to ensure that such tools could one day achieve real-world success. This is, not as an isolated system evolving in the vacuum, but tools in the service of a holistic learning environment.
    
    \subsection{Adaptivity and Knowledge Models}
        \subsubsection{The Promise of Adaptivity}
The key difference between classic textbooks or lecture-based education and most of the recent learning technologies is the promise of adaptivity. This means that the system adapts its behaviour based on the learners' performance, ideally with the goal to maximize their learning intake. In most modern systems, but not all, this maximization is done by a recommender system, the most sophisticated forms of which resolve an instance of the multi-armed bandit problem. Problem which may be solved by one of several different algorithms \parencite{chen_recommendation_2017}. The multi-armed bandit problem is the mathematical formulation of a situation where different actions are proposed, in our case, recommending different learning materials with uncertain pedagogical values, and an agent must decide which actions will maximize a specified reward, here, the students' growth in knowledge. Those systems must make an arbitration between exploiting actions with known, but limited rewards and exploring actions with unknown rewards.

This paradigm allows systems designers to free themselves from the headache caused by having to arbitrate the question relating to the selection of learning material, like their relative difficulty; one exactly on par with the level of the student, or one leveraging other teaching paradigms such as desirable difficulty, or a combination of the two. Depending on the algorithm selected, the promise of adaptive learning is to enable the construction of an individualized profile of the learners' skills, possibly also including a description of theirs learning capacity or rhythm, and to have the system build an optimized curriculum to reach the specified pedagogical goal.

It must  be pointed out that more rule-based systems still exist, and are widely implemented, where the curriculum is designed in advance based on a pedagogical model, playing the role of the recommender systems presented above. Those systems may be relevant when the goal is to teach a specific, well-defined, sets of skills, like primary and secondary schools programs. \textcite{pelanek_adaptive_2025} mentions the Umíme platform in the Czech Republic, that seems to be largely adopted by schools and relies on such architecture. Others systems may not even have adaptivity systems, but simply interactive properties, like the educational programming languages mentioned above, but those are not the focus of the present work.

        \subsubsection{Knowledge Model and Instrumental Goal}
Where recommender systems can make the promise to optimize any given metric, from a YouTube video watch-time to paperclip manufacturing \parencite{bostrom_ethical_2003}, AI systems do not bear the responsibility to define these intermediary instructions, what we call the instrumental goal. This question is at the core of all alignment considerations, and educational systems are no stranger to this probematic. In educational systems, this proxy is based on a knowledge model, also called student model, which are psychometric data from which can be derived a learning model (the evolution of that knowledge through time) which may in turn be used to define the pedagogical value of a teaching material, this metrics being the reward that a multi-armed bandit algorithm would be charged to optimize. The definition of this knowledge model and the nature of the psychometric construct it collects is quintessential to the success of an adaptive learning system, and this definition is the responsibility of the field that the system is intended to teach and psychological models, not AI directly.

    \subsection{Conclusion}
In this section, we analysed the history of educational technologies since the cognitive revolution in the 1950s. We saw the invaluable potential of the still emerging field of AIED, and its promise of adaptivity, together with the risks and opportunities it brings to LRLs. We identified a gap in the literature on LRLs teaching in AIED. If the translation of AIED systems in LRLs may work as long as the topic it is intended to teach is not a language itself, when it comes to teaching languages, the innovations in the field of language educational technologies seems dominated by English, which is an outlier in terms of resources' availability when compared with the majority of the 7000 other languages spoken around the globe. In this context, it seems necessary to rethink how adaptivity can be achieved when most languages around the world don't even possess a scientific descriptive grammar, let alone the dozens of hours of annotated recordings necessary to train speech recognition systems.

%\section{Contributions}
%\abbrv{MCQ}{Multiple Choices Question}
%The most direct and applicable contribution of the present work is the creation of a scalable rapid vocabulary test framework that suits the needs of LRLs. With the implementations of a Breton test already in running in production. This tool will hopefully be used by others to study LRLs acquisition and help improve pedagogical practices in the future.\\
%The second contribution is a technique developed for the rapid calibration of items in an Elo based adaptive MCQs, the "modulo clustering" technic, which presents the calibration process as an exploitation-exploration dilemma. This will help the broader field of AIED to create rapid tests with AI generated items, and help measuring other skills than vocabulary acquisition, from mathematical thinking to translations.
%Finally this work contains epistemological considerations on contruct validity theory, bringing insights on the commercial and academic insentives of psychometrics, it argues in favor of a better understanding of the underlying processes that a given construct attempts to measure, through falsifiable causual mechanisms rather than the traditional correlation-based claims justifications "validation" developped by construct validity theory.


\chapter{Discussions}

\section{Notes on Validity}
In the domain of psychometrics, when the traits measured are latent, it is essential to test the tests, a process called validation. Validation theory is dominated by principles established by \textcite{messick_validity_1987} who unified different aspects of validity (content, criterion, and construct) in one, thus simplifying previous approach to validity.\ \textcite{borsboom_concept_2004} on his end, attempted to simplify construct validity discution a step further by incisting on key concepts in the scientific method, ontology, meaning, causation, by criticising that much of the construct validity discussion about the validation of tests rather than their intrinsic validity. Borsboom argument was, consciously or not, integrated in \cite{kane_validating_2013}, who introduced his argument-based approach to validation, where a given test must be proposed along a set of claims, which must be tested individually.

The idea that a LDT vocabulary test measures vocabulary level can be used to indirectly measure other constrcuts of proficiency, including productive vocabulary, speaking, reading, writing and listening skills has been discussed at length in the literature review along with its limitations. Especially it is understood that a growth in the discrimination skill should not be generalized blindly. That it can interpreted as proficiency growth only as long as the learning activity consist of a legitimate use of the language, where the vocabulary is learned within the context of grammatically correct sentences, whereas taking the test repeatedly may make the test taker being good at taking the test without improving their skills proper. Finally, it is understood that tests score cannot be universally interpreted in a similar way, 1500 in the Welsh test and the French test are not worth the same thing for the following reasons:
\begin{enumerate}
  \item The socio-linguistic context difference makes it difficult to find equivalence in the idea of fluency
  \item The number of items is different, the initialisation of the items rating is based on frequency lists of different lengths
  \item Considering that a wide-spread usage of the tests change the ratings dramatically, the ratings will have a tendency to cluster around the level of the test takers demographics, if many very fluent people take one test, the ratings value will be devaluated, if many beginners take a test, the items rating will be subject to an inflationary effect.
\end{enumerate}

None of the aspects cited above are seen as a problem. Because the test aims at measuring the dynamics, the speed at which the learners learns over periods of weeks and months. For this purpose, our test only need to test the following claims:
\begin{enumerate}
  \item The test is minimalist enough to be prescribed in a few minute, thus making it accessible for recurent use on at least a weekly basis. This claim is validated by design. (Test-retest reliability)
  \item The test is precise enough to capture small variation in vocabulary level. This claim can be declined in several sub-claims:
  \begin{enumerate}
    \item The test is reliable, the same person taking the test several times will obtain a similar score. This is yet to be verified.
    \item There is no ceiling effects, people with a low vocabulary should not have a null score, while fluent speaker should not have a similar score (around 2000 in the initial settings described in the methodology)
    \item The test is accurate, small variations in vocabulary level lead to small variations in score.
  \end{enumerate}
\end{enumerate}